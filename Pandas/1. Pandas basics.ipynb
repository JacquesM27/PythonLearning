{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T20:30:31.242774Z",
     "start_time": "2024-11-03T20:30:30.935220Z"
    }
   },
   "source": [
    "from operator import index\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Series object is a one-dimensional data structure, resembling a list, in which each value has an associated index.",
   "id": "6f742281c1c338a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.231310Z",
     "start_time": "2024-11-03T18:22:10.225846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a Series from a list\n",
    "data = [10, 20, 30, 40]\n",
    "series = pd.Series(data)\n",
    "print(\"Series from a list:\\n\", series)\n",
    "\n",
    "# Creating a Series with custom index\n",
    "data_with_index = pd.Series(data, index=['a', 'b', 'c', 'd'])\n",
    "print(\"\\nSeries with custom index:\\n\", data_with_index)\n",
    "\n",
    "# Creating a Series from a dictionary\n",
    "data_dict = {'apple': 2, 'banana': 3, 'orange': 5}\n",
    "series_dict = pd.Series(data_dict)\n",
    "print(\"\\nSeries from dictionary:\\n\", series_dict)\n"
   ],
   "id": "43c884704f2c8bc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series from a list:\n",
      " 0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "\n",
      "Series with custom index:\n",
      " a    10\n",
      "b    20\n",
      "c    30\n",
      "d    40\n",
      "dtype: int64\n",
      "\n",
      "Series from dictionary:\n",
      " apple     2\n",
      "banana    3\n",
      "orange    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can index the Series object just like a NumPy or dictionary array and perform arithmetic operations on it.",
   "id": "b6aa6ae95c6d6ce1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.300174Z",
     "start_time": "2024-11-03T18:22:10.293413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Accessing values by index\n",
    "print(\"Value at index 'b':\", data_with_index['b'])\n",
    "\n",
    "# Fancy indexing\n",
    "print(\"\\nValues at multiple indices:\\n\", data_with_index[['a', 'c']])\n",
    "\n",
    "# Arithmetic operations\n",
    "series1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "series2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Addition\n",
    "print(\"\\nAddition of two Series:\\n\", series1 + series2)\n",
    "\n",
    "# Scalar operations\n",
    "print(\"\\nSeries multiplied by 2:\\n\", series * 2)\n"
   ],
   "id": "ad4f39e751c6e31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at index 'b': 20\n",
      "\n",
      "Values at multiple indices:\n",
      " a    10\n",
      "c    30\n",
      "dtype: int64\n",
      "\n",
      "Addition of two Series:\n",
      " a    11\n",
      "b    22\n",
      "c    33\n",
      "d    44\n",
      "dtype: int64\n",
      "\n",
      "Series multiplied by 2:\n",
      " 0    20\n",
      "1    40\n",
      "2    60\n",
      "3    80\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A `DataFrame` object is a two-dimensional data structure, similar to a table. It can be created from various sources, such as dictionary lists, `NumPy` arrays , etc.",
   "id": "1a1ef747a338570a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.368654Z",
     "start_time": "2024-11-03T18:22:10.356454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating DataFrame from dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [24, 27, 22],\n",
    "    'City': ['New York', 'San Francisco', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\\n\", df)\n",
    "\n",
    "# Creating DataFrame from list of dictionaries\n",
    "data_list = [\n",
    "    {'Name': 'Alice', 'Age': 24, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 27, 'City': 'San Francisco'},\n",
    "    {'Name': 'Charlie', 'Age': 22, 'City': 'Los Angeles'}\n",
    "]\n",
    "df_from_list = pd.DataFrame(data_list)\n",
    "print(\"\\nDataFrame from list of dictionaries:\\n\", df_from_list)\n",
    "\n",
    "# Creating DataFrame from NumPy array\n",
    "import numpy as np\n",
    "\n",
    "array_data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "df_from_array = pd.DataFrame(array_data, columns=['Column1', 'Column2'])\n",
    "print(\"\\nDataFrame from NumPy array:\\n\", df_from_array)\n"
   ],
   "id": "f460e77625c911db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from dictionary:\n",
      "       Name  Age           City\n",
      "0    Alice   24       New York\n",
      "1      Bob   27  San Francisco\n",
      "2  Charlie   22    Los Angeles\n",
      "\n",
      "DataFrame from list of dictionaries:\n",
      "       Name  Age           City\n",
      "0    Alice   24       New York\n",
      "1      Bob   27  San Francisco\n",
      "2  Charlie   22    Los Angeles\n",
      "\n",
      "DataFrame from NumPy array:\n",
      "    Column1  Column2\n",
      "0        1        2\n",
      "1        3        4\n",
      "2        5        6\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can refer to `DataFrame` columns and rows through `.loc[]`, `.iloc[]`, and directly through column names.\n",
   "id": "a9ad3a341c50f8a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.432492Z",
     "start_time": "2024-11-03T18:22:10.421266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecting a column\n",
    "print(\"Column 'Age':\\n\", df['Age'])\n",
    "\n",
    "# Selecting multiple columns\n",
    "print(\"\\nColumns 'Name' and 'City':\\n\", df[['Name', 'City']])\n",
    "\n",
    "# Row selection by label\n",
    "print(\"\\nRow selection by label:\\n\", df.loc[1])\n",
    "\n",
    "# Row selection by integer position\n",
    "print(\"\\nRow selection by integer position:\\n\", df.iloc[1])\n",
    "\n",
    "# Fancy indexing\n",
    "print(\"\\nSelecting rows where Age > 23:\\n\", df[df['Age'] > 23])\n"
   ],
   "id": "b1cbb4bdc851b53d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Age':\n",
      " 0    24\n",
      "1    27\n",
      "2    22\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Columns 'Name' and 'City':\n",
      "       Name           City\n",
      "0    Alice       New York\n",
      "1      Bob  San Francisco\n",
      "2  Charlie    Los Angeles\n",
      "\n",
      "Row selection by label:\n",
      " Name              Bob\n",
      "Age                27\n",
      "City    San Francisco\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Row selection by integer position:\n",
      " Name              Bob\n",
      "Age                27\n",
      "City    San Francisco\n",
      "Name: 1, dtype: object\n",
      "\n",
      "Selecting rows where Age > 23:\n",
      "     Name  Age           City\n",
      "0  Alice   24       New York\n",
      "1    Bob   27  San Francisco\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Extra explanation:\n",
    "loc - access based on **labels** (label-based)\n",
    "- loc works on the basis of **row and column labels**. We use it if we want to refer to rows or columns based on their names.\n",
    "- loc allows you to select data by specifying labels, that is, column names and row indexes.\n",
    "- It supports both single labels and ranges of labels.\n",
    "\n",
    "- `iloc` - access based on **numeric indexes** (integer-based)\n",
    "- `iloc` works on the basis of numeric **positions** in the DataFrame, i.e. numeric indexes.\n",
    "- It is useful when you want to select data, not looking at the names, but at their positions (e.g. 1st row, 2nd row, etc.).\n",
    "- `iloc` supports **numeric row and column indexes** (counting from zero)."
   ],
   "id": "32a088208c89f51d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.502160Z",
     "start_time": "2024-11-03T18:22:10.487370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_list = [\n",
    "    {'Name': 'Alice', 'Age': 24, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 27, 'City': 'San Francisco'},\n",
    "    {'Name': 'Charlie', 'Age': 22, 'City': 'Los Angeles'}\n",
    "]\n",
    "df_from_list = pd.DataFrame(data_list, index=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "print(\"loc\")\n",
    "print(\"\\nRow selection by label:\\n\", df_from_list.loc[\"a\"])\n",
    "print(\"\\nRow selection by labels:\\n\", df_from_list.loc[\"a\":\"b\"])\n",
    "print(\"\\nRow selection by labels and columns:\\n\", df_from_list.loc[\"a\":\"b\", \"Name\":\"Age\"])\n",
    "\n",
    "print(\"\\n\\niloc\")\n",
    "print(\"\\nRow selection by index:\\n\", df_from_list.iloc[1])\n",
    "print(\"\\nRow selection by indexes:\\n\", df_from_list.iloc[1:3])\n",
    "print(\"\\nRow selection by indexes and columns:\\n\", df_from_list.iloc[1:3, 0:3])"
   ],
   "id": "1dbb96b7c3257df6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc\n",
      "\n",
      "Row selection by label:\n",
      " Name       Alice\n",
      "Age           24\n",
      "City    New York\n",
      "Name: a, dtype: object\n",
      "\n",
      "Row selection by labels:\n",
      "     Name  Age           City\n",
      "a  Alice   24       New York\n",
      "b    Bob   27  San Francisco\n",
      "\n",
      "Row selection by labels and columns:\n",
      "     Name  Age\n",
      "a  Alice   24\n",
      "b    Bob   27\n",
      "\n",
      "\n",
      "iloc\n",
      "\n",
      "Row selection by index:\n",
      " Name              Bob\n",
      "Age                27\n",
      "City    San Francisco\n",
      "Name: b, dtype: object\n",
      "\n",
      "Row selection by indexes:\n",
      "       Name  Age           City\n",
      "b      Bob   27  San Francisco\n",
      "c  Charlie   22    Los Angeles\n",
      "\n",
      "Row selection by indexes and columns:\n",
      "       Name  Age           City\n",
      "b      Bob   27  San Francisco\n",
      "c  Charlie   22    Los Angeles\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas allows you to perform arithmetic and other operations on all table cells.",
   "id": "98d24ad3b350d223"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.567871Z",
     "start_time": "2024-11-03T18:22:10.555857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding a new column\n",
    "df['Salary'] = [50000, 60000, 52000]\n",
    "print(\"DataFrame with new column 'Salary':\\n\", df)\n",
    "\n",
    "# Modifying values in a column based on condition\n",
    "df.loc[df['City'] == 'New York', 'Salary'] += 5000\n",
    "print(\"\\nUpdated DataFrame with modified 'Salary':\\n\", df)\n",
    "\n",
    "# Operations on DataFrame columns\n",
    "df['Bonus'] = df['Salary'] * 0.1\n",
    "print(\"\\nDataFrame with calculated 'Bonus' column:\\n\", df)\n",
    "\n",
    "# Dropping a column\n",
    "df = df.drop(columns=['Bonus'])\n",
    "print(\"\\nDataFrame after dropping 'Bonus' column:\\n\", df)\n"
   ],
   "id": "8d02429b81430a2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with new column 'Salary':\n",
      "       Name  Age           City  Salary\n",
      "0    Alice   24       New York   50000\n",
      "1      Bob   27  San Francisco   60000\n",
      "2  Charlie   22    Los Angeles   52000\n",
      "\n",
      "Updated DataFrame with modified 'Salary':\n",
      "       Name  Age           City  Salary\n",
      "0    Alice   24       New York   55000\n",
      "1      Bob   27  San Francisco   60000\n",
      "2  Charlie   22    Los Angeles   52000\n",
      "\n",
      "DataFrame with calculated 'Bonus' column:\n",
      "       Name  Age           City  Salary   Bonus\n",
      "0    Alice   24       New York   55000  5500.0\n",
      "1      Bob   27  San Francisco   60000  6000.0\n",
      "2  Charlie   22    Los Angeles   52000  5200.0\n",
      "\n",
      "DataFrame after dropping 'Bonus' column:\n",
      "       Name  Age           City  Salary\n",
      "0    Alice   24       New York   55000\n",
      "1      Bob   27  San Francisco   60000\n",
      "2  Charlie   22    Los Angeles   52000\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas allows detecting, removing and filling in missing data.",
   "id": "6889d89975e739fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.641940Z",
     "start_time": "2024-11-03T18:22:10.628187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding NaN values for demonstration\n",
    "import numpy as np\n",
    "\n",
    "df_with_nan = df.copy()\n",
    "df_with_nan.loc[1, 'Salary'] = np.nan\n",
    "df_with_nan.loc[2, 'City'] = np.nan\n",
    "print(\"DataFrame with NaN values:\\n\", df_with_nan)\n",
    "\n",
    "# Detecting NaN values\n",
    "print(\"\\nDetecting NaN values:\\n\", df_with_nan.isna())\n",
    "\n",
    "# Dropping rows with NaN values\n",
    "print(\"\\nDataFrame after dropping rows with NaN:\\n\", df_with_nan.dropna())\n",
    "\n",
    "# Filling NaN values\n",
    "df_filled = df_with_nan.fillna({'Salary': df['Salary'].mean(), 'City': 'Unknown'})\n",
    "print(\"\\nDataFrame after filling NaN values:\\n\", df_filled)\n"
   ],
   "id": "b17956a1c268ad58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with NaN values:\n",
      "       Name  Age           City   Salary\n",
      "0    Alice   24       New York  55000.0\n",
      "1      Bob   27  San Francisco      NaN\n",
      "2  Charlie   22            NaN  52000.0\n",
      "\n",
      "Detecting NaN values:\n",
      "     Name    Age   City  Salary\n",
      "0  False  False  False   False\n",
      "1  False  False  False    True\n",
      "2  False  False   True   False\n",
      "\n",
      "DataFrame after dropping rows with NaN:\n",
      "     Name  Age      City   Salary\n",
      "0  Alice   24  New York  55000.0\n",
      "\n",
      "DataFrame after filling NaN values:\n",
      "       Name  Age           City        Salary\n",
      "0    Alice   24       New York  55000.000000\n",
      "1      Bob   27  San Francisco  55666.666667\n",
      "2  Charlie   22        Unknown  52000.000000\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aggregations allow quick conclusions to be drawn by grouping data.",
   "id": "cf235197dd55995a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.705789Z",
     "start_time": "2024-11-03T18:22:10.695191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a DataFrame for aggregation\n",
    "data = {\n",
    "    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Values': [10, 15, 10, 20, 30, 25]\n",
    "}\n",
    "df_group = pd.DataFrame(data)\n",
    "\n",
    "# Aggregating data by category\n",
    "grouped = df_group.groupby('Category').sum()\n",
    "print(\"Sum of values by Category:\\n\", grouped)\n",
    "\n",
    "# Applying multiple aggregation functions\n",
    "grouped_multiple = df_group.groupby('Category').agg(['sum', 'mean'])\n",
    "print(\"\\nMultiple aggregations by Category:\\n\", grouped_multiple)\n"
   ],
   "id": "823b56803b7f4e9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values by Category:\n",
      "           Values\n",
      "Category        \n",
      "A             25\n",
      "B             30\n",
      "C             55\n",
      "\n",
      "Multiple aggregations by Category:\n",
      "          Values      \n",
      "            sum  mean\n",
      "Category             \n",
      "A            25  12.5\n",
      "B            30  15.0\n",
      "C            55  27.5\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas allows you to combine data from different sources through methods such as `concat` and `merge`.",
   "id": "2160a612920ad732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.772467Z",
     "start_time": "2024-11-03T18:22:10.759423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenation along rows\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']})\n",
    "df2 = pd.DataFrame({'A': ['A3', 'A4', 'A5'], 'B': ['B3', 'B4', 'B5']})\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Concatenated DataFrame:\\n\", df_concat)\n",
    "\n",
    "# Merge example\n",
    "left = pd.DataFrame({'Key': ['K0', 'K1', 'K2'], 'A': ['A0', 'A1', 'A2']})\n",
    "right = pd.DataFrame({'Key': ['K0', 'K1', 'K3'], 'B': ['B0', 'B1', 'B3']})\n",
    "df_merge = pd.merge(left, right, on='Key', how='outer')\n",
    "print(\"\\nMerged DataFrame:\\n\", df_merge)\n"
   ],
   "id": "8ad78ae2993c55cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "     A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n",
      "4  A4  B4\n",
      "5  A5  B5\n",
      "\n",
      "Merged DataFrame:\n",
      "   Key    A    B\n",
      "0  K0   A0   B0\n",
      "1  K1   A1   B1\n",
      "2  K2   A2  NaN\n",
      "3  K3  NaN   B3\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.839636Z",
     "start_time": "2024-11-03T18:22:10.831474Z"
    }
   },
   "cell_type": "code",
   "source": "titanic_df = pd.read_csv(\"../_example_data/titanic.csv\", delimiter=',')",
   "id": "2ab16d37e957a188",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analyze basic statistics of a dataset using `describe()` and `info()`.",
   "id": "6e8be18b07559d0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:10.954205Z",
     "start_time": "2024-11-03T18:22:10.933704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Information about the Titanic dataset:\")\n",
    "titanic_df.info()\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic numeric statistics of the Titanic dataset:\")\n",
    "titanic_df.describe()"
   ],
   "id": "646207ad6fc7707c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the Titanic dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "Basic numeric statistics of the Titanic dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
       "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
       "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
       "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
       "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
       "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
       "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
       "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  418.000000  417.000000  \n",
       "mean     0.392344   35.627188  \n",
       "std      0.981429   55.907576  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.895800  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.500000  \n",
       "max      9.000000  512.329200  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data filtering allows passengers to be selected according to specific criteria, such as surviving passengers or those traveling first class.",
   "id": "bb54629bc393d95c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.136406Z",
     "start_time": "2024-11-03T18:22:11.119731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A selection of passenger survivors\n",
    "survived_passengers = titanic_df[titanic_df['Survived'] == 1]\n",
    "print(\"Passengers who survived:\\n\", survived_passengers.head())\n",
    "\n",
    "# Choice of passengers traveling in first class\n",
    "first_class_passengers = titanic_df[titanic_df['Pclass'] == 1]\n",
    "print(\"\\nPassengers traveling in first class:\\n\", first_class_passengers.head())\n",
    "\n",
    "# A selection of female survivors under the age of 30\n",
    "young_female_survivors = titanic_df[(titanic_df['Sex'] == 'female') & \n",
    "                                    (titanic_df['Age'] < 30) & \n",
    "                                    (titanic_df['Survived'] == 1)]\n",
    "print(\"\\nYoung female survivors:\\n\", young_female_survivors.head())\n"
   ],
   "id": "5340e4204d1e4817",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passengers who survived:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "1           893         1       3   \n",
      "4           896         1       3   \n",
      "6           898         1       3   \n",
      "8           900         1       3   \n",
      "12          904         1       1   \n",
      "\n",
      "                                             Name     Sex   Age  SibSp  Parch  \\\n",
      "1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "6                            Connolly, Miss. Kate  female  30.0      0      0   \n",
      "8       Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female  18.0      0      0   \n",
      "12  Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1      0   \n",
      "\n",
      "     Ticket     Fare Cabin Embarked  \n",
      "1    363272   7.0000   NaN        S  \n",
      "4   3101298  12.2875   NaN        S  \n",
      "6    330972   7.6292   NaN        Q  \n",
      "8      2657   7.2292   NaN        C  \n",
      "12    21228  82.2667   B45        S  \n",
      "\n",
      "Passengers traveling in first class:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "11          903         0       1   \n",
      "12          904         1       1   \n",
      "14          906         1       1   \n",
      "20          912         0       1   \n",
      "22          914         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "11                         Jones, Mr. Charles Cresson    male  46.0      0   \n",
      "12      Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1   \n",
      "14  Chaffee, Mrs. Herbert Fuller (Carrie Constance...  female  47.0      1   \n",
      "20                             Rothschild, Mr. Martin    male  55.0      1   \n",
      "22               Flegenheim, Mrs. Alfred (Antoinette)  female   NaN      0   \n",
      "\n",
      "    Parch       Ticket     Fare Cabin Embarked  \n",
      "11      0          694  26.0000   NaN        S  \n",
      "12      0        21228  82.2667   B45        S  \n",
      "14      0  W.E.P. 5734  61.1750   E31        S  \n",
      "20      0     PC 17603  59.4000   NaN        C  \n",
      "22      0     PC 17598  31.6833   NaN        S  \n",
      "\n",
      "Young female survivors:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "4           896         1       3   \n",
      "8           900         1       3   \n",
      "12          904         1       1   \n",
      "15          907         1       2   \n",
      "18          910         1       3   \n",
      "\n",
      "                                             Name     Sex   Age  SibSp  Parch  \\\n",
      "4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "8       Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female  18.0      0      0   \n",
      "12  Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1      0   \n",
      "15  del Carlo, Mrs. Sebastiano (Argenia Genovesi)  female  24.0      1      0   \n",
      "18                   Ilmakangas, Miss. Ida Livija  female  27.0      1      0   \n",
      "\n",
      "              Ticket     Fare Cabin Embarked  \n",
      "4            3101298  12.2875   NaN        S  \n",
      "8               2657   7.2292   NaN        C  \n",
      "12             21228  82.2667   B45        S  \n",
      "15     SC/PARIS 2167  27.7208   NaN        C  \n",
      "18  STON/O2. 3101270   7.9250   NaN        S  \n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using `groupby()`, we can analyze data in different groups, such as by class or gender.",
   "id": "b46d3122b83e5740"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.225667Z",
     "start_time": "2024-11-03T18:22:11.217863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Average fare by class of travel\n",
    "fare_by_class = titanic_df.groupby('Pclass')['Fare'].mean()\n",
    "print(\"Average fare by class of travel:\\n\", fare_by_class)\n",
    "\n",
    "# Average age of passengers by gender and class of travel\n",
    "age_by_class_and_sex = titanic_df.groupby(['Pclass', 'Sex'])['Age'].mean()\n",
    "print(\"\\nAverage age of passengers by gender and class of travel:\\n\", age_by_class_and_sex)\n",
    "\n",
    "# Survival rate by gender\n",
    "survival_rate_by_sex = titanic_df.groupby('Sex')['Survived'].mean()\n",
    "print(\"\\nSurvival rate by gender:\\n\", survival_rate_by_sex)\n"
   ],
   "id": "3384942b0ebfd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fare by class of travel:\n",
      " Pclass\n",
      "1    94.280297\n",
      "2    22.202104\n",
      "3    12.459678\n",
      "Name: Fare, dtype: float64\n",
      "\n",
      "Average age of passengers by gender and class of travel:\n",
      " Pclass  Sex   \n",
      "1       female    41.333333\n",
      "        male      40.520000\n",
      "2       female    24.376552\n",
      "        male      30.940678\n",
      "3       female    23.073400\n",
      "        male      24.525104\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Survival rate by gender:\n",
      " Sex\n",
      "female    1.0\n",
      "male      0.0\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pivot tables allow analysis of multidimensional data and are similar to clustering, but offer more flexibility.",
   "id": "c21b7c8990c4c590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.324860Z",
     "start_time": "2024-11-03T18:22:11.295491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pivot table showing survival rates by travel class and gender\n",
    "pivot_survival = titanic_df.pivot_table(values='Survived', index='Sex', columns='Pclass', aggfunc='mean')\n",
    "print(\"Survival rate by travel class and gender:\\n\", pivot_survival)\n",
    "\n",
    "# Pivot table showing average fare by port of embarkation and class\n",
    "pivot_fare = titanic_df.pivot_table(values='Fare', index='Embarked', columns='Pclass', aggfunc='mean')\n",
    "print(\"\\nAverage fare by port of embarkation and class:\\n\", pivot_fare)\n",
    "\n",
    "# Pivot table with summary enabled\n",
    "pivot_survival_with_margins = titanic_df.pivot_table(values='Survived', index='Sex', columns='Pclass', aggfunc='mean', margins=True)\n",
    "print(\"\\nSurvival rate with summary for each category:\\n\", pivot_survival_with_margins)\n"
   ],
   "id": "2c43b0b9e5df21bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate by travel class and gender:\n",
      " Pclass    1    2    3\n",
      "Sex                  \n",
      "female  1.0  1.0  1.0\n",
      "male    0.0  0.0  0.0\n",
      "\n",
      "Average fare by port of embarkation and class:\n",
      " Pclass             1          2          3\n",
      "Embarked                                  \n",
      "C         110.073511  20.120445  10.658700\n",
      "Q          90.000000  11.273950   8.998985\n",
      "S          76.677504  23.056090  13.913030\n",
      "\n",
      "Survival rate with summary for each category:\n",
      " Pclass        1         2         3       All\n",
      "Sex                                          \n",
      "female  1.00000  1.000000  1.000000  1.000000\n",
      "male    0.00000  0.000000  0.000000  0.000000\n",
      "All     0.46729  0.322581  0.330275  0.363636\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pivot exercises",
   "id": "ce60921679640e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.400635Z",
     "start_time": "2024-11-03T18:22:11.378365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\n",
    "   \"value\": range(12),\n",
    "   \"variable\": [\"A\"] * 3 + [\"B\"] * 3 + [\"C\"] * 3 + [\"D\"] * 3,\n",
    "   \"date\": pd.to_datetime([\"2020-01-03\", \"2020-01-04\", \"2020-01-05\"] * 4)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "pivoted = df.pivot(index=\"date\", columns=\"variable\", values=\"value\")\n",
    "print(\"\\nPivoted DataFrame:\\n\", pivoted)\n",
    "\n",
    "df[\"value2\"] = df[\"value\"] * 2\n",
    "display(df)\n",
    "pivoted = df.pivot(index=\"date\", columns=\"variable\")\n",
    "print(\"\\nPivoted DataFrame:\\n\", pivoted)"
   ],
   "id": "c1ab3acde97400f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    value variable       date\n",
       "0       0        A 2020-01-03\n",
       "1       1        A 2020-01-04\n",
       "2       2        A 2020-01-05\n",
       "3       3        B 2020-01-03\n",
       "4       4        B 2020-01-04\n",
       "5       5        B 2020-01-05\n",
       "6       6        C 2020-01-03\n",
       "7       7        C 2020-01-04\n",
       "8       8        C 2020-01-05\n",
       "9       9        D 2020-01-03\n",
       "10     10        D 2020-01-04\n",
       "11     11        D 2020-01-05"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoted DataFrame:\n",
      " variable    A  B  C   D\n",
      "date                   \n",
      "2020-01-03  0  3  6   9\n",
      "2020-01-04  1  4  7  10\n",
      "2020-01-05  2  5  8  11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    value variable       date  value2\n",
       "0       0        A 2020-01-03       0\n",
       "1       1        A 2020-01-04       2\n",
       "2       2        A 2020-01-05       4\n",
       "3       3        B 2020-01-03       6\n",
       "4       4        B 2020-01-04       8\n",
       "5       5        B 2020-01-05      10\n",
       "6       6        C 2020-01-03      12\n",
       "7       7        C 2020-01-04      14\n",
       "8       8        C 2020-01-05      16\n",
       "9       9        D 2020-01-03      18\n",
       "10     10        D 2020-01-04      20\n",
       "11     11        D 2020-01-05      22"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "      <th>date</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>C</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>D</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoted DataFrame:\n",
      "            value           value2            \n",
      "variable       A  B  C   D      A   B   C   D\n",
      "date                                         \n",
      "2020-01-03     0  3  6   9      0   6  12  18\n",
      "2020-01-04     1  4  7  10      2   8  14  20\n",
      "2020-01-05     2  5  8  11      4  10  16  22\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.552549Z",
     "start_time": "2024-11-03T18:22:11.513391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pivot_survival_by_embarked = titanic_df.pivot_table(values=\"Survived\", index=\"Embarked\", aggfunc=\"mean\")\n",
    "print(\"\\nSurvival rate by embarked:\\n\", pivot_survival_by_embarked)\n",
    "\n",
    "# fare_by_gender = titanic_df.groupby('Gender')['Fare'].mean()\n",
    "fare_by_sex = titanic_df.pivot_table(values=\"Fare\", index=\"Sex\", aggfunc=\"mean\")\n",
    "print(\"\\nAverage fare by gender:\\n\", fare_by_sex)\n",
    "\n",
    "sib_sp_by_sex_and_class = titanic_df.pivot_table(values=\"SibSp\", index=\"Sex\", columns=\"Pclass\", aggfunc=\"mean\")\n",
    "print(\"\\nSiblings per gender and class\\n\", sib_sp_by_sex_and_class)\n",
    "\n",
    "print(titanic_df['Sex'].unique())\n",
    "print(titanic_df['Pclass'].unique())\n",
    "# pclass_sex_size = titanic_df.pivot_table(values=None, index=\"Sex\", columns=\"Pclass\", aggfunc=\"size\", margins=True)\n",
    "pclass_sex_size = titanic_df.pivot_table(values=None, index=\"Sex\", columns=\"Pclass\", aggfunc=\"size\")\n",
    "# margins=True doesn't work, but I don't know why\n",
    "pclass_sex_size['All'] = pclass_sex_size.sum(axis=1)  # Add all as a column\n",
    "pclass_sex_size.loc['All'] = pclass_sex_size.sum(axis=0)  # Add all as a row\n",
    "print(\"\\nNumber of passengers by class and gender\\n\", pclass_sex_size)\n",
    "\n",
    "survival_by_sex_and_embarked = titanic_df.pivot_table(values=\"Survived\", index=\"Sex\", columns=\"Embarked\", aggfunc=\"mean\", margins=True)\n",
    "print(\"\\nSurvival by gender and emarked\\n\", survival_by_sex_and_embarked)\n"
   ],
   "id": "303b6a51a468460d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Survival rate by embarked:\n",
      "           Survived\n",
      "Embarked          \n",
      "C         0.392157\n",
      "Q         0.521739\n",
      "S         0.325926\n",
      "\n",
      "Average fare by gender:\n",
      "              Fare\n",
      "Sex              \n",
      "female  49.747699\n",
      "male    27.527877\n",
      "\n",
      "Siblings per gender and class\n",
      " Pclass         1         2         3\n",
      "Sex                                 \n",
      "female  0.560000  0.533333  0.583333\n",
      "male    0.403509  0.301587  0.404110\n",
      "['male' 'female']\n",
      "[3 2 1]\n",
      "\n",
      "Number of passengers by class and gender\n",
      " Pclass    1   2    3  All\n",
      "Sex                      \n",
      "female   50  30   72  152\n",
      "male     57  63  146  266\n",
      "All     107  93  218  418\n",
      "\n",
      "Survival by gender and emarked\n",
      " Embarked         C         Q         S       All\n",
      "Sex                                             \n",
      "female    1.000000  1.000000  1.000000  1.000000\n",
      "male      0.000000  0.000000  0.000000  0.000000\n",
      "All       0.392157  0.521739  0.325926  0.363636\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Titanic dataset is missing values, especially in the `Age` and `Cabin` columns . Pandas offers various ways to deal with the missing data.\n",
    "\n",
    "- `ffill` (i.e. forward fill) - Fills in missing values with the previous available value. For example, if there is an empty cell in a column, it will be filled with the value of the cell above it.\n",
    "- `bfill` (or backward fill ) - Fills in missing values with the next available value. For example, an empty cell will be filled with the value of the cell below it."
   ],
   "id": "4734405dd5528596"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.737247Z",
     "start_time": "2024-11-03T18:22:11.724311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking for missing values\n",
    "print(\"Number of missing values in each column:\\n\", titanic_df.isna().sum())\n",
    "\n",
    "# Deleting rows with missing values\n",
    "titanic_no_na = titanic_df.dropna()\n",
    "print(\"\\nDataset after removing rows with missing values:\\n\", titanic_no_na.head())\n",
    "\n",
    "# Filling in missing values in the Age column with the average value\n",
    "titanic_filled = titanic_df.copy()\n",
    "titanic_filled['Age'] = titanic_filled['Age'].fillna(titanic_df['Age'].mean())\n",
    "print(\"\\nDataset with filled values in Age column:\\n\", titanic_filled.head())\n",
    "\n",
    "# Filling missing values with 'forward fill' method for Cabin column\n",
    "titanic_filled['Cabin'] = titanic_filled['Cabin'].ffill()\n",
    "titanic_filled['Cabin'] = titanic_filled['Cabin'].fillna('Unknown')\n",
    "print(\"\\nDataset with filled values in Cabin column:\\n\", titanic_filled.head())\n",
    "# print(titanic_filled.size)\n",
    "# print(titanic_filled[\"Cabin\"].isnull().size)\n",
    "# print(titanic_filled[\"Cabin\"].unique())"
   ],
   "id": "f9afbb1cad63aca7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after removing rows with missing values:\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "12          904         1       1   \n",
      "14          906         1       1   \n",
      "24          916         1       1   \n",
      "26          918         1       1   \n",
      "28          920         0       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "12      Snyder, Mrs. John Pillsbury (Nelle Stevenson)  female  23.0      1   \n",
      "14  Chaffee, Mrs. Herbert Fuller (Carrie Constance...  female  47.0      1   \n",
      "24    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)  female  48.0      1   \n",
      "26                       Ostby, Miss. Helene Ragnhild  female  22.0      0   \n",
      "28                            Brady, Mr. John Bertram    male  41.0      0   \n",
      "\n",
      "    Parch       Ticket      Fare            Cabin Embarked  \n",
      "12      0        21228   82.2667              B45        S  \n",
      "14      0  W.E.P. 5734   61.1750              E31        S  \n",
      "24      3     PC 17608  262.3750  B57 B59 B63 B66        C  \n",
      "26      1       113509   61.9792              B36        C  \n",
      "28      0       113054   30.5000              A21        S  \n",
      "\n",
      "Dataset with filled values in Age column:\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "\n",
      "Dataset with filled values in Cabin column:\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare    Cabin Embarked  \n",
      "0   330911   7.8292  Unknown        Q  \n",
      "1   363272   7.0000  Unknown        S  \n",
      "2   240276   9.6875  Unknown        Q  \n",
      "3   315154   8.6625  Unknown        S  \n",
      "4  3101298  12.2875  Unknown        S  \n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The Pandas library has many functions for processing text data, which is useful for columns such as `Name`.",
   "id": "c9610a7012f49c0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.835841Z",
     "start_time": "2024-11-03T18:22:11.824700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert all names to uppercase\n",
    "titanic_df['Name'] = titanic_df['Name'].str.upper()\n",
    "print(\"Name column after conversion to uppercase:\\n\", titanic_df[['Name']].head())\n",
    "\n",
    "# Extracting the passenger's title from the Name column (e.g. Mr., Mrs.).\n",
    "titanic_df['Title'] = titanic_df['Name'].str.extract(r'([A-Za-z]+)\\.', expand=False)\n",
    "print(\"\\nTitle column extracted from Name:\\n\", titanic_df[['Name', 'Title']].head())\n",
    "\n",
    "# Checking for the presence of the word 'Miss' in the Name column\n",
    "titanic_df['IsMiss'] = titanic_df['Name'].str.contains('MISS')\n",
    "miss_rows = titanic_df[titanic_df[\"IsMiss\"] == True]\n",
    "print(\"\\nIsMiss column showing the names contains the word 'Miss':\\n\", miss_rows[['Name', 'IsMiss']].head())\n"
   ],
   "id": "5e06916b0922109c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name column after conversion to uppercase:\n",
      "                                            Name\n",
      "0                              KELLY, MR. JAMES\n",
      "1              WILKES, MRS. JAMES (ELLEN NEEDS)\n",
      "2                     MYLES, MR. THOMAS FRANCIS\n",
      "3                              WIRZ, MR. ALBERT\n",
      "4  HIRVONEN, MRS. ALEXANDER (HELGA E LINDQVIST)\n",
      "\n",
      "Title column extracted from Name:\n",
      "                                            Name Title\n",
      "0                              KELLY, MR. JAMES    MR\n",
      "1              WILKES, MRS. JAMES (ELLEN NEEDS)   MRS\n",
      "2                     MYLES, MR. THOMAS FRANCIS    MR\n",
      "3                              WIRZ, MR. ALBERT    MR\n",
      "4  HIRVONEN, MRS. ALEXANDER (HELGA E LINDQVIST)   MRS\n",
      "\n",
      "IsMiss column showing the names contains the word 'Miss':\n",
      "                             Name  IsMiss\n",
      "6           CONNOLLY, MISS. KATE    True\n",
      "18  ILMAKANGAS, MISS. IDA LIVIJA    True\n",
      "26  OSTBY, MISS. HELENE RAGNHILD    True\n",
      "36           ROTH, MISS. SARAH A    True\n",
      "37            CACIC, MISS. MANDA    True\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas has strong support for time series data. While the Titanic dataset does not contain date-time data, we'll simulate a date-based column for demonstration purposes.",
   "id": "d24cc4733809e1b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:11.901860Z",
     "start_time": "2024-11-03T18:22:11.887385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding a synthetic date column, assuming each passenger embarked on consecutive days\n",
    "\n",
    "titanic_df['Embark_Date'] = pd.date_range(start='1912-04-01', periods=len(titanic_df), freq='D')\n",
    "print(\"DataFrame with added Embark_Date column:\\n\", titanic_df[['PassengerId', 'Embark_Date']].head())\n",
    "print(\"DataFrame with added Embark_Date column:\\n\", titanic_df[['PassengerId', 'Embark_Date']].tail())\n",
    "\n",
    "# Setting the Embark_Date as the index\n",
    "titanic_df_new_index = titanic_df.copy()\n",
    "titanic_df_new_index.set_index('Embark_Date', inplace=True)\n",
    "print(\"\\nDataFrame with Embark_Date set as index:\\n\", titanic_df_new_index.head())\n",
    "\n",
    "# Extracting year and month\n",
    "titanic_df_new_index['Year'] = titanic_df_new_index.index.year\n",
    "titanic_df_new_index['Month'] = titanic_df_new_index.index.month\n",
    "print(\"\\nExtracted Year and Month columns:\\n\", titanic_df_new_index[['Year', 'Month']].head())\n"
   ],
   "id": "b619a91dd8da348d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with added Embark_Date column:\n",
      "    PassengerId Embark_Date\n",
      "0          892  1912-04-01\n",
      "1          893  1912-04-02\n",
      "2          894  1912-04-03\n",
      "3          895  1912-04-04\n",
      "4          896  1912-04-05\n",
      "DataFrame with added Embark_Date column:\n",
      "      PassengerId Embark_Date\n",
      "413         1305  1913-05-19\n",
      "414         1306  1913-05-20\n",
      "415         1307  1913-05-21\n",
      "416         1308  1913-05-22\n",
      "417         1309  1913-05-23\n",
      "\n",
      "DataFrame with Embark_Date set as index:\n",
      "              PassengerId  Survived  Pclass  \\\n",
      "Embark_Date                                  \n",
      "1912-04-01           892         0       3   \n",
      "1912-04-02           893         1       3   \n",
      "1912-04-03           894         0       2   \n",
      "1912-04-04           895         0       3   \n",
      "1912-04-05           896         1       3   \n",
      "\n",
      "                                                     Name     Sex   Age  \\\n",
      "Embark_Date                                                               \n",
      "1912-04-01                               KELLY, MR. JAMES    male  34.5   \n",
      "1912-04-02               WILKES, MRS. JAMES (ELLEN NEEDS)  female  47.0   \n",
      "1912-04-03                      MYLES, MR. THOMAS FRANCIS    male  62.0   \n",
      "1912-04-04                               WIRZ, MR. ALBERT    male  27.0   \n",
      "1912-04-05   HIRVONEN, MRS. ALEXANDER (HELGA E LINDQVIST)  female  22.0   \n",
      "\n",
      "             SibSp  Parch   Ticket     Fare Cabin Embarked Title  IsMiss  \n",
      "Embark_Date                                                               \n",
      "1912-04-01       0      0   330911   7.8292   NaN        Q    MR   False  \n",
      "1912-04-02       1      0   363272   7.0000   NaN        S   MRS   False  \n",
      "1912-04-03       0      0   240276   9.6875   NaN        Q    MR   False  \n",
      "1912-04-04       0      0   315154   8.6625   NaN        S    MR   False  \n",
      "1912-04-05       1      1  3101298  12.2875   NaN        S   MRS   False  \n",
      "\n",
      "Extracted Year and Month columns:\n",
      "              Year  Month\n",
      "Embark_Date             \n",
      "1912-04-01   1912      4\n",
      "1912-04-02   1912      4\n",
      "1912-04-03   1912      4\n",
      "1912-04-04   1912      4\n",
      "1912-04-05   1912      4\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas offers versatile functions for merging and joining data from different DataFrames, allowing complex database-like operations.",
   "id": "82ff0ac7014eefc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:12.035876Z",
     "start_time": "2024-11-03T18:22:12.022395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a simple DataFrame for demonstration\n",
    "extra_data = pd.DataFrame({\n",
    "    'PassengerId': [892, 893, 894, 895, 896],\n",
    "    'Additional_Info': ['Info1', 'Info2', 'Info3', 'Info4', 'Info5']\n",
    "})\n",
    "\n",
    "# Merging Titanic data with extra_data based on PassengerId\n",
    "merged_df = pd.merge(titanic_df.reset_index(), extra_data, on='PassengerId', how='left')\n",
    "print(\"Merged DataFrame:\\n\", merged_df[['PassengerId', 'Additional_Info']].head())\n",
    "print(\"Merged DataFrame:\\n\", merged_df[['PassengerId', 'Additional_Info']].tail())\n",
    "\n",
    "print(titanic_df.columns)\n",
    "# Joining DataFrames using index\n",
    "extra_info = pd.DataFrame({\n",
    "    'Fare_Discount': [5, 0, 10, 15, 0],\n",
    "    'Embarked': ['Q', 'S', 'Q', 'S', 'S']\n",
    "}, index=[892, 893, 894, 895, 896])\n",
    "\n",
    "# Setting PassengerId as index in titanic_df to enable join\n",
    "if not titanic_df.index.name == 'PassengerId':\n",
    "    titanic_df.set_index('PassengerId', inplace=True)\n",
    "joined_df = titanic_df.join(extra_info, how='left', lsuffix='_extra')\n",
    "print(\"\\nJoined DataFrame:\\n\", joined_df[['Fare_Discount', 'Embarked', \"Embarked_extra\"]].head())\n"
   ],
   "id": "61719e03362bcf93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "    PassengerId Additional_Info\n",
      "0          892           Info1\n",
      "1          893           Info2\n",
      "2          894           Info3\n",
      "3          895           Info4\n",
      "4          896           Info5\n",
      "Merged DataFrame:\n",
      "      PassengerId Additional_Info\n",
      "413         1305             NaN\n",
      "414         1306             NaN\n",
      "415         1307             NaN\n",
      "416         1308             NaN\n",
      "417         1309             NaN\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'IsMiss',\n",
      "       'Embark_Date'],\n",
      "      dtype='object')\n",
      "\n",
      "Joined DataFrame:\n",
      "              Fare_Discount Embarked Embarked_extra\n",
      "PassengerId                                       \n",
      "892                    5.0        Q              Q\n",
      "893                    0.0        S              S\n",
      "894                   10.0        Q              Q\n",
      "895                   15.0        S              S\n",
      "896                    0.0        S              S\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `apply` method with lambda functions allows complex transformations and custom logic for each row or column in a DataFrame.",
   "id": "288726e101692c05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:12.069670Z",
     "start_time": "2024-11-03T18:22:12.057843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a column that categorizes passengers based on age\n",
    "titanic_df['Age_Group'] = titanic_df['Age'].apply(lambda x: 'Child' if x < 18 else 'Adult' if x < 60 else 'Senior')\n",
    "print(\"DataFrame with Age_Group column:\\n\", titanic_df[['Age', 'Age_Group']].head())\n",
    "\n",
    "# Creating a custom function to categorize Fare\n",
    "def fare_category(fare):\n",
    "    if fare < 10:\n",
    "        return 'Low'\n",
    "    elif fare < 50:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "    \n",
    "# Applying the custom function to create a new Fare_Category column\n",
    "titanic_df[\"Fare_Category\"] = titanic_df[\"Fare\"].apply(fare_category)\n",
    "print(\"\\nDataFrame with Fare_Category column:\\n\", titanic_df[['Fare', 'Fare_Category']].head())"
   ],
   "id": "f331a38d87f92725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Age_Group column:\n",
      "               Age Age_Group\n",
      "PassengerId                \n",
      "892          34.5     Adult\n",
      "893          47.0     Adult\n",
      "894          62.0    Senior\n",
      "895          27.0     Adult\n",
      "896          22.0     Adult\n",
      "\n",
      "DataFrame with Fare_Category column:\n",
      "                 Fare Fare_Category\n",
      "PassengerId                       \n",
      "892           7.8292           Low\n",
      "893           7.0000           Low\n",
      "894           9.6875           Low\n",
      "895           8.6625           Low\n",
      "896          12.2875        Medium\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Handling categorical data effectively can help optimize memory usage and improve analysis performance.\n",
    "\n",
    "## What is a `category` data type ?\n",
    "- The `category` data type in pandas is a special data type that stores values as categories, instead of strings (str) or integers (int). This makes the column act like an enumeration in programming, where values are represented as internal codes, rather than as full texts or numbers.\n",
    "\n",
    "## The main advantages of using a category type are:\n",
    "- **Memory saving**: The category type stores each unique value only once and represents the remaining values by a reference to that original value (usually in the form of a numeric code). Thus, for columns containing repeated values, it uses less memory.\n",
    "- **Speeding up processing**: Pandas can process columns of type category, especially for grouping and filtering operations, which speeds up data analysis.\n",
    "\n",
    "Pandas allows you to check the DataFrame's  memory usage before and after conversion using the `.memory_usage(deep=True)` method . After conversion to `category` type , the memory occupied by these columns should decrease, since pandas only stores unique values and their codes.\n"
   ],
   "id": "9bf66f706d1df41f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:22:12.149211Z",
     "start_time": "2024-11-03T18:22:12.133484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nMemory usage of the DataFrame before conversion (in bytes):\\n\", titanic_df.memory_usage(deep=True))\n",
    "# Converting Sex to a categorical data type\n",
    "titanic_df['Sex'] = titanic_df['Sex'].astype('category')\n",
    "print(\"Data types after converting 'Sex' to categorical:\\n\", titanic_df.dtypes)\n",
    "\n",
    "# Converting multiple columns to categorical types\n",
    "titanic_df[['Pclass', 'Embarked', 'Age_Group', 'Fare_Category']] = titanic_df[['Pclass', 'Embarked', 'Age_Group', 'Fare_Category']].astype('category')\n",
    "# print(\"\\nData types after converting multiple columns to categorical:\\n\", titanic_df.dtypes)\n",
    "\n",
    "# Checking memory usage before and after conversion\n",
    "print(\"\\nMemory usage of the DataFrame (in bytes):\\n\", titanic_df.memory_usage(deep=True))"
   ],
   "id": "2a43f835d64bd77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage of the DataFrame before conversion (in bytes):\n",
      " Index             3344\n",
      "Survived          3344\n",
      "Pclass            3344\n",
      "Name             31970\n",
      "Sex              22458\n",
      "Age               3344\n",
      "SibSp             3344\n",
      "Parch             3344\n",
      "Ticket           23356\n",
      "Fare              3344\n",
      "Cabin            15294\n",
      "Embarked         20900\n",
      "Title            21636\n",
      "IsMiss             418\n",
      "Embark_Date       3344\n",
      "Age_Group        22672\n",
      "Fare_Category    22361\n",
      "dtype: int64\n",
      "\n",
      "Memory usage of the DataFrame (in bytes):\n",
      " Index             3344\n",
      "Survived          3344\n",
      "Pclass             550\n",
      "Name             31970\n",
      "Sex                634\n",
      "Age               3344\n",
      "SibSp             3344\n",
      "Parch             3344\n",
      "Ticket           23356\n",
      "Fare              3344\n",
      "Cabin            15294\n",
      "Embarked           676\n",
      "Title            21636\n",
      "IsMiss             418\n",
      "Embark_Date       3344\n",
      "Age_Group          689\n",
      "Fare_Category      686\n",
      "dtype: int64\n",
      "             Survived Pclass                                          Name  \\\n",
      "PassengerId                                                                  \n",
      "892                 0      3                              KELLY, MR. JAMES   \n",
      "893                 1      3              WILKES, MRS. JAMES (ELLEN NEEDS)   \n",
      "894                 0      2                     MYLES, MR. THOMAS FRANCIS   \n",
      "895                 0      3                              WIRZ, MR. ALBERT   \n",
      "896                 1      3  HIRVONEN, MRS. ALEXANDER (HELGA E LINDQVIST)   \n",
      "\n",
      "                Sex   Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \\\n",
      "PassengerId                                                                \n",
      "892            male  34.5      0      0   330911   7.8292   NaN        Q   \n",
      "893          female  47.0      1      0   363272   7.0000   NaN        S   \n",
      "894            male  62.0      0      0   240276   9.6875   NaN        Q   \n",
      "895            male  27.0      0      0   315154   8.6625   NaN        S   \n",
      "896          female  22.0      1      1  3101298  12.2875   NaN        S   \n",
      "\n",
      "            Title  IsMiss Embark_Date Age_Group Fare_Category  \n",
      "PassengerId                                                    \n",
      "892            MR   False  1912-04-01     Adult           Low  \n",
      "893           MRS   False  1912-04-02     Adult           Low  \n",
      "894            MR   False  1912-04-03    Senior           Low  \n",
      "895            MR   False  1912-04-04     Adult           Low  \n",
      "896           MRS   False  1912-04-05     Adult        Medium  \n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Dummy variables are essential for converting categorical variables into a format that machine learning algorithms can use.\n",
    "\n",
    "## What are “dummy” variables?\n",
    "Dummy variables are binary columns (0 or 1) that represent categories in categorical columns. For each unique value in a categorical column, a new column is created that takes the value 1 if that category is present in the row, or 0 otherwise.\n",
    "## How does `pd.get_dummies()` work ?\n",
    "The pd.get_dummies() function converts categorical columns into binary variables as follows:\n",
    "In each column, such as `Sex`, `Pclass`, `Embarked`, or `Fare_Category`, each unique value is converted into a separate column.\n",
    "In these new columns, a value of `1` means that the category is present in that row, and `0` means that it is not.\n",
    "## Why `drop_first=True`?\n",
    "The `drop_first=True` option makes us omit the first category from each categorical column, which prevents collinearity (the so-called dummy variable trap). If we have, for example, a `Sex` column with the values `male` and `female`, we only need one binary column, e.g. `Sex_male`, because:\n",
    "- `Sex_male = 1` means male,\n",
    "- `Sex_male = 0` means female.\n",
    "\n",
    "In this way, models avoid redundancy in the data.\n"
   ],
   "id": "4a485d34cb7d742a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T18:24:32.525537Z",
     "start_time": "2024-11-03T18:24:32.511932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converting categorical columns into dummy/indicator variables\n",
    "titanic_dummies = pd.get_dummies(titanic_df, columns=['Pclass', 'Sex', 'Embarked', 'Fare_Category'], drop_first=True)\n",
    "print(\"DataFrame with dummy variables:\\n\", titanic_dummies.head())\n"
   ],
   "id": "284ec7d1aab724e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with dummy variables:\n",
      "              Survived                                          Name   Age  \\\n",
      "PassengerId                                                                 \n",
      "892                 0                              KELLY, MR. JAMES  34.5   \n",
      "893                 1              WILKES, MRS. JAMES (ELLEN NEEDS)  47.0   \n",
      "894                 0                     MYLES, MR. THOMAS FRANCIS  62.0   \n",
      "895                 0                              WIRZ, MR. ALBERT  27.0   \n",
      "896                 1  HIRVONEN, MRS. ALEXANDER (HELGA E LINDQVIST)  22.0   \n",
      "\n",
      "             SibSp  Parch   Ticket     Fare Cabin Title  IsMiss Embark_Date  \\\n",
      "PassengerId                                                                   \n",
      "892              0      0   330911   7.8292   NaN    MR   False  1912-04-01   \n",
      "893              1      0   363272   7.0000   NaN   MRS   False  1912-04-02   \n",
      "894              0      0   240276   9.6875   NaN    MR   False  1912-04-03   \n",
      "895              0      0   315154   8.6625   NaN    MR   False  1912-04-04   \n",
      "896              1      1  3101298  12.2875   NaN   MRS   False  1912-04-05   \n",
      "\n",
      "            Age_Group  Pclass_2  Pclass_3  Sex_male  Embarked_Q  Embarked_S  \\\n",
      "PassengerId                                                                   \n",
      "892             Adult     False      True      True        True       False   \n",
      "893             Adult     False      True     False       False        True   \n",
      "894            Senior      True     False      True        True       False   \n",
      "895             Adult     False      True      True       False        True   \n",
      "896             Adult     False      True     False       False        True   \n",
      "\n",
      "             Fare_Category_Low  Fare_Category_Medium  \n",
      "PassengerId                                           \n",
      "892                       True                 False  \n",
      "893                       True                 False  \n",
      "894                       True                 False  \n",
      "895                       True                 False  \n",
      "896                      False                  True  \n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `agg` function allows for custom aggregations on multiple columns and functions in a single operation.",
   "id": "1382a2da04a9a62f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T19:29:27.077299Z",
     "start_time": "2024-11-03T19:29:27.065391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggregating multiple columns with different functions\n",
    "aggregation = titanic_df.agg({\n",
    "    'Age': ['mean', 'min', 'max'],\n",
    "    'Fare': ['sum', 'mean', 'std'],\n",
    "    'Survived': 'sum'\n",
    "})\n",
    "print(\"Custom aggregation on Age, Fare, and Survived:\\n\", aggregation)\n",
    "\n",
    "# Aggregating grouped data\n",
    "grouped_agg = titanic_df.groupby('Pclass', observed=False).agg({\n",
    "    'Fare': ['min', 'max', 'mean'],\n",
    "    'Age': ['mean', 'median'],\n",
    "    'Survived': 'sum'\n",
    "})\n",
    "print(\"\\nGrouped custom aggregation on Fare, Age, and Survived by Pclass:\\n\", grouped_agg)\n"
   ],
   "id": "6fc4944e1a7cd33b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom aggregation on Age, Fare, and Survived:\n",
      "            Age          Fare  Survived\n",
      "mean  30.27259     35.627188       NaN\n",
      "min    0.17000           NaN       NaN\n",
      "max   76.00000           NaN       NaN\n",
      "sum        NaN  14856.537600     152.0\n",
      "std        NaN     55.907576       NaN\n",
      "\n",
      "Grouped custom aggregation on Fare, Age, and Survived by Pclass:\n",
      "           Fare                             Age        Survived\n",
      "           min       max       mean       mean median      sum\n",
      "Pclass                                                        \n",
      "1       0.0000  512.3292  94.280297  40.918367   42.0       50\n",
      "2       9.6875   73.5000  22.202104  28.777500   26.5       30\n",
      "3       3.1708   69.5500  12.459678  24.027945   24.0       72\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Sorting and ranking are essential for organizing data based on specific criteria.\n",
    "\n",
    "rank - sorts the data based on the class column. In this case, we are counting who paid the most for a ticket in a particular class. As a result, we get a column containing consecutive ordinal numbers (they are not divided by class, it is a common column for each class based on the sorted value (we sort by class and by ticket price))\n",
    "\n",
    "\n",
    "| Pclass | Fare | Fare_Rank (`method='min'`) | Fare_Rank (`method='max'`) |\n",
    "|--------|------|----------------------------|----------------------------|\n",
    "| 3      | 15   | 1                          | 1                          |\n",
    "| 3      | 12   | 2                          | 2                          |\n",
    "| 3      | 10   | 3                          | 5                          |\n",
    "| 3      | 10   | 3                          | 5                          |\n",
    "| 3      | 10   | 3                          | 5                          |\n",
    "| 3      | 5    | 6                          | 6                          |\n",
    "\n",
    "- For `method='min'`: All passengers who paid 10 units get a ranking of `3` (the lowest possible of their ranking).\n",
    "- For `method='max'`: All passengers with a ticket for 10 units get a ranking of `5` (the highest possible of their ranking places).\n",
    "\n",
    "### Why might this be useful?\n",
    "\n",
    "- **`method='min'`** is often used when you want to assign a uniform, **conservative ranking** (the lowest possible), making it easier to sort and analyze the data.\n",
    "- **`method='max'`** can be useful when you want to see what the **maximum ranking** would be for this value, e.g. to evaluate positions in the lower ranking range. \n",
    "\n",
    "Which method to choose depends on how you want to treat cases with identical values."
   ],
   "id": "fdb83db4b906777f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T20:08:50.824918Z",
     "start_time": "2024-11-03T20:08:50.813470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sorting by Age in ascending order\n",
    "sorted_by_age = titanic_df.sort_values(by='Age', ascending=True)\n",
    "print(\"Data sorted by Age:\\n\", sorted_by_age[['Age', 'Name']].head())\n",
    "\n",
    "# Sorting by multiple columns, e.g., Pclass and Fare\n",
    "sorted_multi = titanic_df.sort_values(by=['Pclass', 'Fare'], ascending=[True, False])\n",
    "print(\"\\nData sorted by Pclass and Fare:\\n\", sorted_multi[['Pclass', 'Fare', 'Name']].head())\n",
    "\n",
    "# Ranking based on Fare within each class\n",
    "# titanic_df['Fare_Rank'] = titanic_df.groupby('Pclass', observed=False)['Fare'].rank(method='min', ascending=False)\n",
    "titanic_df['Fare_Rank'] = titanic_df.groupby('Pclass', observed=False)['Fare'].rank(method='max', ascending=False)\n",
    "# print(\"\\nFare rank within each class:\\n\", titanic_df[['Pclass', 'Fare', 'Fare_Rank']].head())\n",
    "# print(\"\\nFare rank within each class:\\n\", titanic_df[titanic_df[\"Pclass\"] == 1][['Pclass', 'Fare', 'Fare_Rank']].head())\n",
    "sorted_by_fare_rank = titanic_df.sort_values(by='Fare_Rank', ascending=True)\n",
    "print(\"\\nFare rank within each class:\\n\", sorted_by_fare_rank[['Pclass', 'Fare', 'Fare_Rank']].head())\n"
   ],
   "id": "e7d3a5d45995bbf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sorted by Age:\n",
      "               Age                                     Name\n",
      "PassengerId                                               \n",
      "1246         0.17  DEAN, MISS. ELIZABETH GLADYS MILLVINA\"\"\n",
      "1093         0.33  DANBOM, MASTER. GILBERT SIGVARD EMANUEL\n",
      "1173         0.75           PEACOCK, MASTER. ALFRED EDWARD\n",
      "1199         0.83                AKS, MASTER. PHILIP FRANK\n",
      "1142         0.92                    WEST, MISS. BARBARA J\n",
      "\n",
      "Data sorted by Pclass and Fare:\n",
      "             Pclass      Fare  \\\n",
      "PassengerId                    \n",
      "1235             1  512.3292   \n",
      "945              1  263.0000   \n",
      "961              1  263.0000   \n",
      "916              1  262.3750   \n",
      "951              1  262.3750   \n",
      "\n",
      "                                                          Name  \n",
      "PassengerId                                                     \n",
      "1235         CARDEZA, MRS. JAMES WARBURTON MARTINEZ (CHARLO...  \n",
      "945                                 FORTUNE, MISS. ETHEL FLORA  \n",
      "961                        FORTUNE, MRS. MARK (MARY MCDOUGALD)  \n",
      "916            RYERSON, MRS. ARTHUR LARNED (EMILY MARIA BORIE)  \n",
      "951                                CHAUDANSON, MISS. VICTORINE  \n",
      "\n",
      "Fare rank within each class:\n",
      "             Pclass      Fare  Fare_Rank\n",
      "PassengerId                            \n",
      "1235             1  512.3292        1.0\n",
      "1244             2   73.5000        2.0\n",
      "1104             2   73.5000        2.0\n",
      "945              1  263.0000        3.0\n",
      "961              1  263.0000        3.0\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Window functions, such as `rolling` and `expanding`, are useful for performing calculations over a sliding window.",
   "id": "7c61237c330e48cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T20:11:50.148184Z",
     "start_time": "2024-11-03T20:11:50.140612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adding a moving average of Fare over a 5-row rolling window\n",
    "titanic_df['Rolling_Fare_Avg'] = titanic_df['Fare'].rolling(window=5).mean()\n",
    "print(\"Data with 5-row rolling average of Fare:\\n\", titanic_df[['Fare', 'Rolling_Fare_Avg']].head(15))\n",
    "\n",
    "# Expanding window sum of Survived to calculate cumulative survival count\n",
    "titanic_df['Cumulative_Survived'] = titanic_df['Survived'].expanding().sum()\n",
    "print(\"\\nCumulative count of Survived passengers:\\n\", titanic_df[['Survived', 'Cumulative_Survived']].head(10))\n"
   ],
   "id": "759d8593881ce013",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 5-row rolling average of Fare:\n",
      "                 Fare  Rolling_Fare_Avg\n",
      "PassengerId                           \n",
      "892           7.8292               NaN\n",
      "893           7.0000               NaN\n",
      "894           9.6875               NaN\n",
      "895           8.6625               NaN\n",
      "896          12.2875           9.09334\n",
      "897           9.2250           9.37250\n",
      "898           7.6292           9.49834\n",
      "899          29.0000          13.36084\n",
      "900           7.2292          13.07418\n",
      "901          24.1500          15.44668\n",
      "902           7.8958          15.18084\n",
      "903          26.0000          18.85500\n",
      "904          82.2667          29.50834\n",
      "905          26.0000          33.26250\n",
      "906          61.1750          40.66750\n",
      "\n",
      "Cumulative count of Survived passengers:\n",
      "              Survived  Cumulative_Survived\n",
      "PassengerId                               \n",
      "892                 0                  0.0\n",
      "893                 1                  1.0\n",
      "894                 0                  1.0\n",
      "895                 0                  1.0\n",
      "896                 1                  2.0\n",
      "897                 0                  2.0\n",
      "898                 1                  3.0\n",
      "899                 0                  3.0\n",
      "900                 1                  4.0\n",
      "901                 0                  4.0\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In time series analysis, `resample` allows aggregations by time periods, which can be helpful in summarizing data.",
   "id": "b8e08713630d0240"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T20:14:34.459951Z",
     "start_time": "2024-11-03T20:14:34.452645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reset index to make Embark_Date available again\n",
    "titanic_df.reset_index(inplace=True)\n",
    "\n",
    "# Set Embark_Date as index and resample monthly\n",
    "titanic_df.set_index('Embark_Date', inplace=True)\n",
    "monthly_survival = titanic_df['Survived'].resample('ME').sum()\n",
    "print(\"Monthly survival count:\\n\", monthly_survival)\n",
    "\n",
    "# Resampling by quarter to calculate average Fare\n",
    "quarterly_fare_avg = titanic_df['Fare'].resample('QE').mean()\n",
    "print(\"\\nQuarterly average fare:\\n\", quarterly_fare_avg)\n"
   ],
   "id": "4ecdbba5a20ef197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly survival count:\n",
      " Embark_Date\n",
      "1912-04-30    12\n",
      "1912-05-31    11\n",
      "1912-06-30    13\n",
      "1912-07-31    12\n",
      "1912-08-31     8\n",
      "1912-09-30    14\n",
      "1912-10-31    10\n",
      "1912-11-30    13\n",
      "1912-12-31    10\n",
      "1913-01-31     9\n",
      "1913-02-28     8\n",
      "1913-03-31    11\n",
      "1913-04-30    11\n",
      "1913-05-31    10\n",
      "Freq: ME, Name: Survived, dtype: int64\n",
      "\n",
      "Quarterly average fare:\n",
      " Embark_Date\n",
      "1912-06-30    40.547254\n",
      "1912-09-30    31.227976\n",
      "1912-12-31    33.415805\n",
      "1913-03-31    34.334262\n",
      "1913-06-30    40.767057\n",
      "Freq: QE-DEC, Name: Fare, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Outliers can skew analysis, so detecting and handling them is often necessary in data preprocessing.",
   "id": "7ed613c1a84e0a2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T20:23:19.210209Z",
     "start_time": "2024-11-03T20:23:19.198292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Detecting outliers in the Fare column using the IQR method\n",
    "Q1 = titanic_df['Fare'].quantile(0.25)\n",
    "Q3 = titanic_df['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(\"Q1: \", Q1)\n",
    "print(\"Q3: \", Q3)\n",
    "print(\"IQR: \", IQR)\n",
    "\n",
    "outliers = titanic_df[(titanic_df['Fare'] < (Q1 - 1.5 * IQR)) | (titanic_df['Fare'] > (Q3 + 1.5 * IQR))]\n",
    "print(\"Outliers in Fare column:\\n\", outliers[['Fare', 'Pclass', 'Name']])\n",
    "\n",
    "# Handling outliers by capping Fare values at the 5th and 95th percentiles\n",
    "titanic_df['Fare'] = np.where(titanic_df['Fare'] > titanic_df['Fare'].quantile(0.95), titanic_df['Fare'].quantile(0.95), titanic_df['Fare'])\n",
    "titanic_df['Fare'] = np.where(titanic_df['Fare'] < titanic_df['Fare'].quantile(0.05), titanic_df['Fare'].quantile(0.05), titanic_df['Fare'])\n",
    "print(\"\\nFare column after outlier capping:\\n\", titanic_df[['Fare']].describe())\n"
   ],
   "id": "3dede315c729558e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:  7.8958\n",
      "Q3:  31.5\n",
      "IQR:  23.6042\n",
      "Outliers in Fare column:\n",
      "                  Fare Pclass  \\\n",
      "Embark_Date                    \n",
      "1912-04-13    82.2667      1   \n",
      "1912-04-25   151.5500      1   \n",
      "1912-05-19    76.2917      1   \n",
      "1912-05-24   151.5500      1   \n",
      "1912-05-30   151.5500      1   \n",
      "1912-06-04   151.5500      1   \n",
      "1912-06-09   151.5500      1   \n",
      "1912-06-14   151.5500      1   \n",
      "1912-06-15   151.5500      1   \n",
      "1912-06-21   151.5500      1   \n",
      "1912-07-06    78.8500      1   \n",
      "1912-07-24   151.5500      1   \n",
      "1912-07-28    75.2417      1   \n",
      "1912-08-20   151.5500      1   \n",
      "1912-08-21   151.5500      1   \n",
      "1912-08-29    83.1583      1   \n",
      "1912-09-04   151.5500      1   \n",
      "1912-09-27    83.1583      1   \n",
      "1912-09-29    83.1583      1   \n",
      "1912-10-02   151.5500      1   \n",
      "1912-10-06    69.5500      3   \n",
      "1912-10-14   134.5000      1   \n",
      "1912-10-20   151.5500      1   \n",
      "1912-10-30    73.5000      2   \n",
      "1912-11-04   151.5500      1   \n",
      "1912-11-05   151.5500      1   \n",
      "1912-11-21    71.2833      1   \n",
      "1912-11-23    75.2500      1   \n",
      "1912-11-26   106.4250      1   \n",
      "1912-11-29   134.5000      1   \n",
      "1912-12-09   136.7792      1   \n",
      "1912-12-27    75.2417      1   \n",
      "1912-12-29   136.7792      1   \n",
      "1913-01-13    82.2667      1   \n",
      "1913-01-19    81.8583      1   \n",
      "1913-02-01   151.5500      1   \n",
      "1913-02-03    93.5000      1   \n",
      "1913-02-09   135.6333      1   \n",
      "1913-02-11   146.5208      1   \n",
      "1913-02-19   151.5500      1   \n",
      "1913-02-22    79.2000      1   \n",
      "1913-03-09    69.5500      3   \n",
      "1913-03-10   151.5500      1   \n",
      "1913-03-19    73.5000      2   \n",
      "1913-03-27    69.5500      3   \n",
      "1913-04-01    69.5500      3   \n",
      "1913-04-07   134.5000      1   \n",
      "1913-04-10    81.8583      1   \n",
      "1913-04-11   151.5500      1   \n",
      "1913-04-26    93.5000      1   \n",
      "1913-05-03    79.2000      1   \n",
      "1913-05-06   151.5500      1   \n",
      "1913-05-13   151.5500      1   \n",
      "1913-05-17    90.0000      1   \n",
      "1913-05-20   108.9000      1   \n",
      "\n",
      "                                                          Name  \n",
      "Embark_Date                                                     \n",
      "1912-04-13       SNYDER, MRS. JOHN PILLSBURY (NELLE STEVENSON)  \n",
      "1912-04-25     RYERSON, MRS. ARTHUR LARNED (EMILY MARIA BORIE)  \n",
      "1912-05-19     BUCKNELL, MRS. WILLIAM ROBERT (EMMA ELIZA WARD)  \n",
      "1912-05-24                          FORTUNE, MISS. ETHEL FLORA  \n",
      "1912-05-30                         CHAUDANSON, MISS. VICTORINE  \n",
      "1912-06-04                         RYERSON, MASTER. JOHN BORIE  \n",
      "1912-06-09                 FORTUNE, MRS. MARK (MARY MCDOUGALD)  \n",
      "1912-06-14                                GEIGER, MISS. AMALIE  \n",
      "1912-06-15                                  KEEPING, MR. EDWIN  \n",
      "1912-06-21                                  STRAUS, MR. ISIDOR  \n",
      "1912-07-06   CAVENDISH, MRS. TYRELL WILLIAM (JULIA FLORENCE...  \n",
      "1912-07-24              STRAUS, MRS. ISIDOR (ROSALIE IDA BLUN)  \n",
      "1912-07-28                                BEATTIE, MR. THOMSON  \n",
      "1912-08-20                                DANIELS, MISS. SARAH  \n",
      "1912-08-21                          RYERSON, MR. ARTHUR LARNED  \n",
      "1912-08-29               EARNSHAW, MRS. BOULTON (OLIVE POTTER)  \n",
      "1912-09-04                                   BIRD, MISS. ELLEN  \n",
      "1912-09-27   COMPTON, MRS. ALEXANDER TAYLOR (MARY ELIZA ING...  \n",
      "1912-09-29                    COMPTON, MR. ALEXANDER TAYLOR JR  \n",
      "1912-10-02   DOUGLAS, MRS. FREDERICK CHARLES (MARY HELENE B...  \n",
      "1912-10-06                                     SAGE, MISS. ADA  \n",
      "1912-10-14                     SPEDDEN, MASTER. ROBERT DOUGLAS  \n",
      "1912-10-20                              ASTOR, COL. JOHN JACOB  \n",
      "1912-10-30                           DEACON, MR. PERCY WILLIAM  \n",
      "1912-11-04                            WICK, MR. GEORGE DENNICK  \n",
      "1912-11-05        WIDENER, MRS. GEORGE DUNTON (ELEANOR ELKINS)  \n",
      "1912-11-21                           CUMINGS, MR. JOHN BRADLEY  \n",
      "1912-11-23                            WARREN, MR. FRANK MANLEY  \n",
      "1912-11-26         DOUGLAS, MRS. WALTER DONALD (MAHALA DUTTON)  \n",
      "1912-11-29                        SPEDDEN, MR. FREDERIC OAKLEY  \n",
      "1912-12-09                            CLARK, MR. WALTER MILLER  \n",
      "1912-12-27                        MCCAFFRY, MR. THOMAS FRANCIS  \n",
      "1912-12-29       CLARK, MRS. WALTER MILLER (VIRGINIA MCDOWELL)  \n",
      "1913-01-13                          SNYDER, MR. JOHN PILLSBURY  \n",
      "1913-01-19                               DODGE, DR. WASHINGTON  \n",
      "1913-02-01                ALLISON, MR. HUDSON JOSHUA CREIGHTON  \n",
      "1913-02-03                          HAYS, MR. CHARLES MELVILLE  \n",
      "1913-02-09               WHITE, MRS. JOHN STUART (ELLA HOLMES)  \n",
      "1913-02-11                       SPENCER, MR. WILLIAM AUGUSTUS  \n",
      "1913-02-19                              KREUCHEN, MISS. EMILIE  \n",
      "1913-02-22         ROSENSHINE, MR. GEORGE (MR GEORGE THORNE\")\"  \n",
      "1913-03-09                               SAGE, MR. JOHN GEORGE  \n",
      "1913-03-10   CARDEZA, MRS. JAMES WARBURTON MARTINEZ (CHARLO...  \n",
      "1913-03-19                                 DIBDEN, MR. WILLIAM  \n",
      "1913-03-27                         SAGE, MASTER. WILLIAM HENRY  \n",
      "1913-04-01                      SAGE, MRS. JOHN (ANNIE BULLEN)  \n",
      "1913-04-07                           WILSON, MISS. HELEN ALICE  \n",
      "1913-04-10               DODGE, MRS. WASHINGTON (RUTH VIDAVER)  \n",
      "1913-04-11                            BOWEN, MISS. GRACE SCOTT  \n",
      "1913-04-26                          PAYNE, MR. VIVIAN PONSONBY  \n",
      "1913-05-03   FROLICHER-STEHLI, MRS. MAXMILLIAN (MARGARETHA ...  \n",
      "1913-05-06                             BONNELL, MISS. CAROLINE  \n",
      "1913-05-13                          WIDENER, MR. GEORGE DUNTON  \n",
      "1913-05-17     MINAHAN, MRS. WILLIAM EDWARD (LILLIAN E THORPE)  \n",
      "1913-05-20                        OLIVA Y OCANA, DONA. FERMINA  \n",
      "\n",
      "Fare column after outlier capping:\n",
      "              Fare\n",
      "count  417.000000\n",
      "mean    31.251430\n",
      "std     37.923239\n",
      "min      7.229200\n",
      "25%      7.895800\n",
      "50%     14.454200\n",
      "75%     31.500000\n",
      "max    151.550000\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pandas has built-in support for simple plots, making it easy to visualize data without needing additional libraries like matplotlib for basic graphs.",
   "id": "b502e45bcfd81713"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T20:38:27.765190Z",
     "start_time": "2024-11-03T20:38:27.656444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plotting the distribution of ages\n",
    "titanic_df['Age'].plot(kind='hist', title='Age Distribution', bins=20)\n",
    "# plt.show()\n",
    "\n",
    "# Bar plot of survival rate by class\n",
    "titanic_df.groupby('Pclass', observed=False)['Survived'].mean().plot(kind='bar', title='Survival Rate by Class')\n",
    "# plt.show()\n",
    "\n",
    "# Line plot of monthly survival count (requires Embark_Date as index)\n",
    "monthly_survival.plot(kind='line', title='Monthly Survival Count')\n",
    "plt.show()\n"
   ],
   "id": "c8afb9fa190894c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
